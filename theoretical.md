---
layout: page
title: theoretical
permalink: /notes/
---

Attached are all the articles and challenges (for my school's ML Club) that I've written here. Most, if not all, will be rendered with LaTeX, which I've discussed [here][7].


## Articles 
- Gradient Descent Revisited As Euler's Method [[post][1]]
- Hidden Taylor Series in Theoretical Machine Learning [[post][2]]
- Attempts at Closed-Form Logistic Regression [[post][3]]

[1]: /jekyll/update/2022/10/11/gradient-descent-euler/
[2]: /jekyll/update/2022/09/26/mltaylorseries-copy/
[3]: /jekyll/update/2022/09/20/closed-form-logreg/

## Challenges
- When More Parameters Reduce Training Performance: Linear Neural Networks [[pdf][4]]
- Gradient Descent in Depth & Create Your Own Regressor Challenge [[pdf][5]]
- Artifical Neural Networks + Autoencoders [[pdf][6]]

[5]: /notes/Gradient_Descent_ML_Club_Challenge.pdf
[4]: /notes/Linear_Regression_Layer.pdf
[6]: /notes/Artificial_Neural_Networks_ML_Club_Worksheet.pdf
[7]: /jekyll/update/2022/11/04/latex